# Codette Training Data Reference

**Quick reference for accessing Codette's trained knowledge**

## Accessing Training Data

### Via API Endpoint
```bash
GET http://localhost:8000/api/training/context
```

Returns complete training context with:
- `daw_functions` - 30+ DAW functions across 7 categories
- `ui_components` - 6 UI components with controls
- `codette_abilities` - 10 AI teaching abilities
- Plus existing: standards, plugins, analysis, musical knowledge

### In Python
```python
from codette_training_data import get_training_context

context = get_training_context()
daw_funcs = context["daw_functions"]
ui_comps = context["ui_components"]
abilities = context["codette_abilities"]
```

---

## DAW Functions Structure

Each function includes:
```python
{
    "name": "play()",                           # Function signature
    "description": "Start playback...",         # What it does
    "category": "transport",                    # Function category
    "parameters": [],                           # Parameter list
    "returns": "void",                          # Return type
    "affects_audio": True,                      # Audio processing
    "affects_cpu": True,                        # CPU usage
    "hotkey": "Space",                          # Keyboard shortcut
    "implementation": "togglePlay() in DAWContext.tsx",
    "python_equivalent": "engine.play_audio()",
    "use_case": "Begin playback of session",
    "tips": ["Tip 1", "Tip 2", "Tip 3"]
}
```

### DAW Function Categories
| Category | Count | Functions |
|----------|-------|-----------|
| transport | 7 | play, stop, pause, seek, set_tempo, set_loop, set_metronome |
| tracks | 6 | add_track, delete_track, select_track, toggle_mute, toggle_solo, toggle_arm |
| mixer | 4 | set_volume, set_pan, set_input_gain, update_track |
| effects | 4 | add_effect, remove_effect, set_effect_parameter, bypass_effect |
| waveform | 4 | get_waveform_data, get_duration, zoom_waveform, scale_waveform |
| automation | 3 | record_automation, add_automation_point, clear_automation |
| project | 2 | upload_audio_file, create_project |

**Total: 30 documented functions**

---

## UI Components Structure

Each component includes:
```python
{
    "description": "Main transport and control toolbar...",
    "location": "src/components/TopBar.tsx",
    "size": "Full width, ~60px height",
    "functions": ["play", "stop", "record", ...],
    "sections": {
        "Transport": [
            {"button": "Play", "hotkey": "Space", "function": "togglePlay"},
            ...
        ],
        ...
    },
    "teaching_tips": ["Tip 1", "Tip 2", "Tip 3"]
}
```

### UI Components
1. **TopBar** - Transport controls (8 buttons)
2. **Mixer** - Track mixing (3 sliders + 3 buttons)
3. **WaveformAdjuster** - Timeline controls (4 zoom/scale buttons)
4. **PluginRack** - Effects chain (add/remove/param controls)
5. **AutomationLane** - Automation editing (record/clear/draw)
6. **TrackList** - Track organization (add/delete/select)

---

## Codette Abilities Structure

Each ability includes:
```python
{
    "ability": "Explain any DAW function...",           # Capability name
    "description": "Codette can provide detailed...",   # What it does
    "example_prompt": "Explain what seek() does",       # Example question
    "example_response": "The seek() function jumps...",  # Example answer
    "training_data": "DAW_FUNCTIONS dictionary",        # Source
    "when_to_use": "User wants to understand a function",
    "skill_level": "Beginner+",
    "related_abilities": ["teach_mixing_techniques"]
}
```

### Codette's 10 Abilities
1. **explain_daw_functions** - Explain DAW functions with parameters
2. **teach_mixing_techniques** - Suggest mixing chains and settings
3. **analyze_session_health** - Assess mix quality
4. **teach_production_workflow** - Guide through production stages
5. **suggest_parameter_values** - Recommend effect settings
6. **explain_ui_components** - Describe UI elements
7. **provide_learning_paths** - Suggest learning sequences
8. **explain_audio_theory** - Teach audio concepts
9. **detect_issues** - Identify and fix problems
10. **suggest_enhancements** - Recommend creative improvements

---

## Using Codette Chat

### Endpoint
```
POST http://localhost:8000/codette/chat
Content-Type: application/json

{
  "message": "Your question here",
  "perspective": "neuralnets"  (optional)
}
```

### Response Format
```json
{
  "response": "Codette's answer...",
  "perspective": "neuralnets",
  "confidence": 0.92
}
```

### Question Types Supported

#### DAW Function Questions
```
"Explain the play() function"
"What does seek() do?"
"How do I use automation?"
"Tell me about set_volume()"
```

#### UI Component Questions
```
"What does the Mixer do?"
"Explain the TopBar"
"Tell me about the PluginRack"
"How do I use WaveformAdjuster?"
```

#### Ability Questions
```
"Can you explain DAW functions?"
"How do you teach mixing?"
"What's your capability?"
"How can you help me learn?"
```

#### General Questions
```
"How do I mix?"
"What's good gain staging?"
"Tell me about compression"
"What effects should I use?"
```

### Confidence Scores
- **0.92+** - Direct training data match (DAW function/UI component)
- **0.85-0.91** - Codette ability or general knowledge
- **0.75-0.84** - Audio theory or best practices
- **0.5-0.74** - Fallback or general question
- **<0.5** - Uncertain response

---

## Integration Examples

### React Component Integration
```typescript
import { useCodetteTeaching } from '../hooks/useTeachingMode';

export function MyComponent() {
  const { queryCodette } = useCodetteTeaching();
  
  const handleLearn = async () => {
    const response = await queryCodette("Explain play() function");
    console.log(response);
  };
  
  return <button onClick={handleLearn}>Learn</button>;
}
```

### Direct API Call
```typescript
const response = await fetch('http://localhost:8000/codette/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: "How do I set track volume?",
    perspective: "neuralnets"
  })
});

const data = await response.json();
console.log(data.response);  // Codette's answer
console.log(data.confidence); // How confident (0-1)
```

### Server Integration (Python)
```python
from codette_training_data import get_training_context

context = get_training_context()

# Access specific DAW function
play_func = context["daw_functions"]["transport"]["play"]
print(play_func["description"])  # "Start playback from current position"

# Access UI component
mixer = context["ui_components"]["Mixer"]
print(mixer["description"])  # "Track mixing controls..."

# Access Codette ability
explain = context["codette_abilities"]["explain_daw_functions"]
print(explain["when_to_use"])  # "User wants to understand a function"
```

---

## Performance Notes

### Response Times
- Training data lookup: <10ms
- Match against DAW functions: <5ms
- Match against UI components: <5ms
- Match against abilities: <5ms
- Total response: ~50-100ms

### Data Size
- DAW Functions: ~30KB
- UI Components: ~15KB
- Codette Abilities: ~10KB
- Total training data: ~500KB (including existing knowledge)

### Server Memory
- Base FastAPI: ~50MB
- Training data loaded: +150MB
- Codette engine: +30MB
- Total: ~230MB

---

## Extending Training Data

### Adding a New DAW Function
```python
DAW_FUNCTIONS["transport"]["pause"] = {
    "name": "pause()",
    "description": "Pause playback at current position",
    "category": "transport",
    "parameters": [],
    "returns": "void",
    "affects_audio": True,
    "affects_cpu": False,
    "hotkey": "Ctrl+Space",
    "implementation": "togglePlay() logic in DAWContext",
    "python_equivalent": "engine.pause_audio()",
    "use_case": "Temporary stop while keeping playback position",
    "tips": ["Pause keeps your place - good for iterating"]
}
```

### Adding a New UI Component
```python
UI_COMPONENTS["NewComponent"] = {
    "description": "What this component does",
    "location": "src/components/NewComponent.tsx",
    "size": "Width, Height",
    "functions": ["function1", "function2"],
    "sections": {...},
    "teaching_tips": ["Tip 1", "Tip 2"]
}
```

### Adding a New Codette Ability
```python
CODETTE_ABILITIES["new_ability"] = {
    "ability": "Ability name",
    "description": "What it does",
    "example_prompt": "User question example",
    "example_response": "Codette's answer example",
    "training_data": "Source of knowledge",
    "when_to_use": "When to apply this ability",
    "skill_level": "Beginner/Intermediate/Advanced",
    "related_abilities": ["other_ability"]
}
```

---

## Training Data File

**Location**: `codette_training_data.py` (line ~1700+)

**Size**: ~1,800 lines (full file with all training data)

**Update Frequency**: As features are added to CoreLogic Studio

**Versioning**: 
- Core audio training: v1.0 (stable)
- DAW/UI training: v1.0 (new - November 25, 2025)
- Combined: v7.0 (matches CoreLogic Studio version)

---

## Troubleshooting

### Codette not responding
1. Check server: `curl http://localhost:8000/health`
2. Verify training: `curl http://localhost:8000/api/training/context`
3. Check logs for errors

### Training data not loading
1. Verify `codette_training_data.py` syntax
2. Check imports in `codette_server.py`
3. Restart server: `python codette_server.py`

### Low confidence scores
- Question may not match training data
- Consider rephrasing question
- Check if new function needs to be added to training

---

## Files Modified

1. **codette_training_data.py** - Added DAW_FUNCTIONS, UI_COMPONENTS, CODETTE_ABILITIES
2. **codette_server.py** - Enhanced /codette/chat endpoint with training data integration
3. **CODETTE_TRAINING_COMPLETE.md** - This comprehensive documentation

---

## Version History

| Date | Version | Changes |
|------|---------|---------|
| Nov 24, 2025 | 6.0 | Initial CoreLogic Studio setup |
| Nov 25, 2025 | 7.0 | Complete DAW function documentation |
| Nov 25, 2025 | 7.0.1 | Codette training complete + API integration |

---

**Codette is ready to teach!** ðŸŽµ
